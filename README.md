# Telecom Call Data Engineering Pipeline (PySpark)

A complete **Telecom Call Detail Records (CDR) Data Engineering Pipeline** built using **PySpark** and the modern **Medallion Architecture (Bronze â†’ Silver â†’ Gold)**.

This project processes raw telecom call transaction data from CSV, cleans and transforms it into Parquet format, applies anomaly detection rules, builds a Star Schema model, and generates business KPIs for telecom analytics.

It is designed as a **portfolio-quality Data Engineering project** demonstrating real-world ETL workflows, scalable lakehouse design, and analytics-ready outputs.

---

## ğŸš€ Project Overview

Telecom companies generate billions of call records daily.  
These records are used for:

- Revenue reporting  
- Customer usage analytics  
- Fraud and anomaly detection  
- Operational monitoring  

Raw call transaction data must be transformed into structured, analytics-ready datasets.

This pipeline performs:

- Raw data ingestion into a Data Lake (Bronze)
- Data cleaning and standardization (Silver)
- Call anomaly detection (Long calls, International calls)
- Star Schema modeling for analytics (Gold)
- Business KPI queries for insights

---

## ğŸ— Pipeline Architecture (Medallion Design)

```
Raw CSV Call Records
        â†“
Bronze Layer (Raw Parquet)
        â†“
Silver Layer (Cleaned + Standardized Parquet)
        â†“
Anomaly Detection Layer (Flagged Calls)
        â†“
Gold Layer (Star Schema Tables)
        â†“
Business Queries + Telecom KPI Reports
```

---

## ğŸ“‚ Project Structure

```
telecom_cdr_pipeline/
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ config.py
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ call_records.csv
â”‚
â”œâ”€â”€ jobs/
â”‚   â”œâ”€â”€ bronze_ingestion.py
â”‚   â”œâ”€â”€ silver_cleaning.py
â”‚   â”œâ”€â”€ anomaly_detection.py
â”‚   â”œâ”€â”€ gold_star_schema.py
â”‚   â””â”€â”€ business_queries.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ spark_session.py
â”‚   â”œâ”€â”€ schema_definitions.py
â”‚   â””â”€â”€ helpers.py
â”‚
â””â”€â”€ output/
    â”œâ”€â”€ bronze/
    â”œâ”€â”€ silver/
    â”œâ”€â”€ gold/
    â””â”€â”€ reports/
```

---

## ğŸ“Œ Data Source

The pipeline uses a sample telecom dataset:

`data/call_records.csv`

Example:

```csv
call_id,customer_id,customer_name,call_type,duration_minutes,call_cost,call_date,city,country
1,C001,John Smith,Local,15,5,2025-01-05,New York,USA
2,C002,Amina Rahman,International,45,25,2025-01-06,Boston,USA
3,C003,Sarah Lee,Local,200,60,2025-01-08,Chicago,USA
```

---


## âš™ï¸ Technologies Used

- **Python**
- **PySpark**
- **Parquet Storage Format**
- **Medallion Data Lake Architecture**
- **Anomaly Detection Engineering**
- **Star Schema Data Modeling**
- **Telecom KPI Analytics Queries**

---

## ğŸš€ Pipeline Jobs

---

### ğŸ¥‰ Bronze Layer: Raw Data Ingestion

**File:** `jobs/bronze_ingestion.py`

Responsibilities:

- Read raw call transaction CSV data
- Apply schema validation
- Store raw records in Parquet format

Output:

```
output/bronze/
```

---

### ğŸ¥ˆ Silver Layer: Data Cleaning & Transformation

**File:** `jobs/silver_cleaning.py`

Transformations applied:

- Remove duplicate call records
- Handle missing values
- Convert call_date into proper DateType

Output:

```
output/silver/
```

---
